{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b11ab95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import torch \n",
    "from PIL import Image    # used to load image\n",
    "from torch import nn, save, load \n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader \n",
    "from torchvision import datasets \n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6b774505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get datasets  \n",
    "# save to data folder, download True, train True, data transform to tensor\n",
    "train = datasets.MNIST(root=\"data\", download=True, train=True, transform=ToTensor())# dataset = DataLoader(train, 32)   # batch size 32\n",
    "dataset = DataLoader(train, 32)   # convert batch into 32 images\n",
    "# 1,28,28 - classes 0-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1148ff3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "tensor(2)\n",
      "tensor(2)\n",
      "tensor(4)\n",
      "tensor(9)\n"
     ]
    }
   ],
   "source": [
    "# Image Classifier Neural Network \n",
    "# subclass nn.Module, implement __init__ and __forward__ methods\n",
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()     # subclass model\n",
    "        # create model using Sequencetial API\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, (3,3)),   # input channel, 1=black/white, 32 filters or kernels, shape of 3 by 3 \n",
    "            nn.ReLU(),     # activation\n",
    "            nn.Conv2d(32, 64, (3,3)),    # output 64 channels\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, (3,3)),\n",
    "            nn.ReLU(),            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*(28-6)*(28-6), 10)  # 64 channels *(28 - 6(shaving off 2 pixel at each time * 3 layers)) , need 10 outputs (0..9)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Instance of the neural network, loss, optimizer \n",
    "clf = ImageClassifier().to('cpu') #.to('cpu')    create an instance \n",
    "opt = Adam(clf.parameters(), lr=1e-3)    # create optimizer Adam , learning rate \n",
    "loss_fn = nn.CrossEntropyLoss()     # loss function\n",
    "            \n",
    "def train():\n",
    "    for epoch in range(5):    # 10 epoches\n",
    "        for batch in dataset:    # batch data \n",
    "            X, y = batch \n",
    "            X, y = X.to('cpu'), y.to('cpu')\n",
    "            yhat = clf(X)    # make prediction \n",
    "            loss = loss_fn(yhat, y)    # calculate loss_fn\n",
    "\n",
    "            # apply backprop\n",
    "            opt.zero_grad()    # zero out gradients \n",
    "            loss.backward()    # calculate gradients\n",
    "            opt.step()     # apply gradient descents \n",
    "\n",
    "        print(f\"Epoch:{epoch} loss is {loss.item()}\")\n",
    "\n",
    "    with open('model_state.pt', 'wb') as f:   # save model \n",
    "        save(clf.state_dict(), f)\n",
    "    \n",
    "def inference(image_file: str) -> str: \n",
    "    with open('model_state.pt', 'rb') as f:\n",
    "        clf.load_state_dict(load(f))    # load weights into clf \n",
    "    img = Image.open(image_file)    # open image\n",
    "    img_tensor = ToTensor()(img).unsqueeze(0).to('cpu')    # convert to tensor , unsqueeze for single image\n",
    "    print(torch.argmax(clf(img_tensor)))\n",
    "\n",
    "    \n",
    "    \n",
    "# Training flow, typical python function \n",
    "if __name__ == \"__main__\":\n",
    "    # train model, comment this after training\n",
    "#     train()\n",
    "    \n",
    "    # inference image for number \n",
    "    inference('./img_0.jpeg')\n",
    "    inference('./img_2.jpeg')\n",
    "    inference('./img_6.jpeg')\n",
    "    inference('./img_9_to_1.jpeg')\n",
    "    inference('./img_9.jpeg')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd119e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbac96a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
